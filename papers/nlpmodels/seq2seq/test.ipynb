{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 6.20 GiB (download: 6.20 GiB, generated: Unknown size, total: 6.20 GiB) to /Users/jonirajalaa/tensorflow_datasets/wmt14_translate/fr-en/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 53.29 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 44.58 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 37.87 url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 657632379/657632379 [00:00<00:00, 21869307267.83 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 30.73 url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 264.21 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 162.79 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 124.24 url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 918311367/918311367 [00:00<00:00, 82316621569.40 MiB/s] \n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 81.15 url/s] \n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [10:20<00:00, 155.23s/ file]\n",
      "Dl Size...: 2688 MiB [10:20,  4.33 MiB/s]\n",
      "Dl Completed...: 2 url [10:20, 310.47s/ url]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 8/8 [00:14<00:00,  1.80s/ file]\n",
      "Dl Size...: 100%|██████████| 76/76 [00:14<00:00,  5.28 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:14<00:00, 14.41s/ url]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 2/2 [07:11<00:00, 215.51s/ file]\n",
      "Dl Size...: 100%|██████████| 2474/2474 [07:11<00:00,  5.74 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [07:11<00:00, 431.01s/ url]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 244.32 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 186.67 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 155.52 url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 38654961/38654961 [00:00<00:00, 1213316701.41 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 30.59 url/s] \n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset, info \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwmt14_translate/fr-en\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_supervised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/load.py:649\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[1;32m    644\u001b[0m     name,\n\u001b[1;32m    645\u001b[0m     data_dir,\n\u001b[1;32m    646\u001b[0m     builder_kwargs,\n\u001b[1;32m    647\u001b[0m     try_gcs,\n\u001b[1;32m    648\u001b[0m )\n\u001b[0;32m--> 649\u001b[0m \u001b[43m_download_and_prepare_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/load.py:508\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[0;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m    507\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 508\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:691\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[1;32m    699\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py:1584\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m split_name, generator \u001b[38;5;129;01min\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   1573\u001b[0m       split_generators\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1574\u001b[0m       desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating splits...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1575\u001b[0m       unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m splits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1576\u001b[0m       leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1577\u001b[0m   ):\n\u001b[1;32m   1578\u001b[0m     filename_template \u001b[38;5;241m=\u001b[39m naming\u001b[38;5;241m.\u001b[39mShardedFileTemplate(\n\u001b[1;32m   1579\u001b[0m         split\u001b[38;5;241m=\u001b[39msplit_name,\n\u001b[1;32m   1580\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1581\u001b[0m         data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m   1582\u001b[0m         filetype_suffix\u001b[38;5;241m=\u001b[39mpath_suffix,\n\u001b[1;32m   1583\u001b[0m     )\n\u001b[0;32m-> 1584\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[43msplit_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_split_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_shuffling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_shuffling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     split_info_futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;66;03m# Process the result of the beam pipeline.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/split_builder.py:341\u001b[0m, in \u001b[0;36mSplitBuilder.submit_split_generation\u001b[0;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Depending on the type of generator, we use the corresponding\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# `_build_from_xyz` method.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generator, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m--> 341\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Otherwise, beam required\u001b[39;00m\n\u001b[1;32m    343\u001b[0m   unknown_generator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    344\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid split generator value for split `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    345\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected generator or apache_beam object. Got: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    346\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(generator)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    347\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/split_builder.py:418\u001b[0m, in \u001b[0;36mSplitBuilder._build_from_generator\u001b[0;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[1;32m    416\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     utils\u001b[38;5;241m.\u001b[39mreraise(e, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to encode example:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m   \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m shard_lengths, total_size \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m    421\u001b[0m split_info \u001b[38;5;241m=\u001b[39m splits_lib\u001b[38;5;241m.\u001b[39mSplitInfo(\n\u001b[1;32m    422\u001b[0m     name\u001b[38;5;241m=\u001b[39msplit_name,\n\u001b[1;32m    423\u001b[0m     shard_lengths\u001b[38;5;241m=\u001b[39mshard_lengths,\n\u001b[1;32m    424\u001b[0m     num_bytes\u001b[38;5;241m=\u001b[39mtotal_size,\n\u001b[1;32m    425\u001b[0m     filename_template\u001b[38;5;241m=\u001b[39mfilename_template,\n\u001b[1;32m    426\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/writer.py:238\u001b[0m, in \u001b[0;36mWriter.write\u001b[0;34m(self, key, example)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, example):\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Writes given Example.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m  The given example is not directly written to the tfrecord file, but to a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    example: the Example to write to the tfrecord file.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   serialized_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuffler\u001b[38;5;241m.\u001b[39madd(key, serialized_example)\n\u001b[1;32m    240\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/tensorflow_datasets/core/example_serializer.py:98\u001b[0m, in \u001b[0;36mExampleSerializer.serialize_example\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: TreeDict[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Serialize the given example.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    serialize_proto: `str`, the serialized `tf.train.Example` proto\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1086\u001b[0m, in \u001b[0;36m_AddSerializeToStringMethod.<locals>.SerializeToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIsInitialized():\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m message_mod\u001b[38;5;241m.\u001b[39mEncodeError(\n\u001b[1;32m   1084\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is missing required fields: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m   1085\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDESCRIPTOR\u001b[38;5;241m.\u001b[39mfull_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFindInitializationErrors())))\n\u001b[0;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializePartialToString\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1095\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.SerializePartialToString\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSerializePartialToString\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1094\u001b[0m   out \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[0;32m-> 1095\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InternalSerialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1115\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[0;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m field_descriptor, field_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mListFields():\n\u001b[0;32m-> 1115\u001b[0m     \u001b[43mfield_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m tag_bytes, value_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unknown_fields:\n\u001b[1;32m   1117\u001b[0m     write_bytes(tag_bytes)\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/encoder.py:768\u001b[0m, in \u001b[0;36mMessageEncoder.<locals>.EncodeField\u001b[0;34m(write, value, deterministic)\u001b[0m\n\u001b[1;32m    766\u001b[0m write(tag)\n\u001b[1;32m    767\u001b[0m local_EncodeVarint(write, value\u001b[38;5;241m.\u001b[39mByteSize(), deterministic)\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InternalSerialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1115\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[0;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m field_descriptor, field_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mListFields():\n\u001b[0;32m-> 1115\u001b[0m     \u001b[43mfield_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m tag_bytes, value_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unknown_fields:\n\u001b[1;32m   1117\u001b[0m     write_bytes(tag_bytes)\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/encoder.py:827\u001b[0m, in \u001b[0;36mMapEncoder.<locals>.EncodeField\u001b[0;34m(write, value, deterministic)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m value_keys:\n\u001b[1;32m    826\u001b[0m   entry_msg \u001b[38;5;241m=\u001b[39m message_type\u001b[38;5;241m.\u001b[39m_concrete_class(key\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39mvalue[key])\n\u001b[0;32m--> 827\u001b[0m   \u001b[43mencode_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/encoder.py:768\u001b[0m, in \u001b[0;36mMessageEncoder.<locals>.EncodeField\u001b[0;34m(write, value, deterministic)\u001b[0m\n\u001b[1;32m    766\u001b[0m write(tag)\n\u001b[1;32m    767\u001b[0m local_EncodeVarint(write, value\u001b[38;5;241m.\u001b[39mByteSize(), deterministic)\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InternalSerialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/fun/jonigrad/venv/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:1099\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[0;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mSerializePartialToString \u001b[38;5;241m=\u001b[39m SerializePartialToString\n\u001b[0;32m-> 1099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInternalSerialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, write_bytes, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m     deterministic \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1102\u001b[0m         api_implementation\u001b[38;5;241m.\u001b[39mIsPythonDefaultSerializationDeterministic())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load('wmt14_translate/fr-en', split=['train', 'validation'], with_info=True, as_supervised=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[0]\n",
    "validation_dataset = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dataset_to_numpy(dataset):\n",
    "    french_sentences = []\n",
    "    german_sentences = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        french_sentences.append(example['translation']['fr'].numpy().decode('utf-8'))\n",
    "        german_sentences.append(example['translation']['de'].numpy().decode('utf-8'))\n",
    "    \n",
    "    return np.array(french_sentences), np.array(german_sentences)\n",
    "train_engalish, train_german = dataset_to_numpy(train_dataset[0])\n",
    "validation_engalish, validation_german = dataset_to_numpy(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "en_vocab = dict()\n",
    "fr_vocab = dict()\n",
    "\n",
    "for sentence in en_data:\n",
    "    for word in sentence:\n",
    "        if word not in en_vocab: en_vocab[word] = len(en_vocab)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
