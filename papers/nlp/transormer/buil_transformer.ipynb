{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jonigrad.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Module):\n",
    "    def __init__(self, d_model=512, num_heads=8):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.wq = Linear(d_model, d_model)\n",
    "        self.wk = Linear(d_model, d_model)\n",
    "        self.wv = Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDPAttention(self.depth)\n",
    "\n",
    "        self.linear = Linear(d_model, d_model)\n",
    "        self.norm = LayerNorm((d_model,))\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.reshape(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.transpose(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "    def combine_heads(self, x, batch_size):        \n",
    "        x = x.transpose(0, 2, 1, 3).reshape(batch_size, -1, self.d_model)  # (batch_size, seq_len, d_model)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.shape[0]\n",
    "        \n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.attention.forward(q, k, v, mask)\n",
    "        scaled_attention = self.combine_heads(scaled_attention, batch_size)\n",
    "        \n",
    "        output = self.linear(scaled_attention)\n",
    "        return self.norm(output + self.combine_heads(q, batch_size))  \n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        batch_size = dL_dy.shape[0]\n",
    "        \n",
    "        # Gradient of the norm layer\n",
    "        dL_dnorm = self.norm.backward(dL_dy)\n",
    "\n",
    "        # Gradient through the final linear layer\n",
    "        dL_dlinear = self.linear.backward(dL_dnorm)\n",
    "\n",
    "        # Reshape back to split heads format\n",
    "        dL_dlinear_heads = self.split_heads(dL_dlinear, batch_size)\n",
    "        \n",
    "        # Gradient through attention mechanism\n",
    "        dL_dattn_q, dL_dattn_k, dL_dattn_v = self.attention.backward(dL_dlinear_heads)\n",
    "        \n",
    "        # Gradient through the input projections\n",
    "        dL_dq = self.wq.backward(self.combine_heads(dL_dattn_q, batch_size))\n",
    "        dL_dk = self.wk.backward(self.combine_heads(dL_dattn_k, batch_size))\n",
    "        dL_dv = self.wv.backward(self.combine_heads(dL_dattn_v, batch_size))\n",
    "        \n",
    "        return dL_dq, dL_dk, dL_dv\n",
    "\n",
    "class ScaledDPAttention(Module):\n",
    "    def __init__(self, depth):\n",
    "        super().__init__()\n",
    "        self.scale = np.sqrt(depth)\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        self.q, self.k, self.v = q, k, v\n",
    "        self.mask = mask\n",
    "\n",
    "        self.scores = np.matmul(q, k.transpose(0, 1, 3, 2)) / self.scale\n",
    "        if mask is not None:\n",
    "            self.mask = mask[:, :, :self.scores.shape[-2], :self.scores.shape[-1]]\n",
    "            self.scores = np.where(self.mask, self.scores, -1e9)\n",
    "            \n",
    "        self.attn = self.softmax(self.scores)\n",
    "        self.output = np.matmul(self.attn, v)\n",
    "        return self.output, self.attn\n",
    "    \n",
    "    def backward(self, dL_dy):\n",
    "        # Gradient of the output wrt. attention weights\n",
    "        dL_dattn = np.matmul(dL_dy, self.v.transpose(0, 1, 3, 2))\n",
    "        \n",
    "        # Gradient of the output wrt. v\n",
    "        dL_dv = np.matmul(self.attn.transpose(0, 1, 3, 2), dL_dy)\n",
    "        \n",
    "        # Backward pass through softmax\n",
    "        datt_scores = self.softmax.backward(dL_dattn)\n",
    "        \n",
    "        if self.mask is not None:\n",
    "            datt_scores = np.where(self.mask, datt_scores, 0)\n",
    "\n",
    "        # Gradients of the scores wrt. q, k\n",
    "        dL_dq = np.matmul(datt_scores, self.k) / self.scale\n",
    "        dL_dk = np.matmul(datt_scores.transpose(0, 1, 3, 2), self.q) / self.scale\n",
    "\n",
    "\n",
    "        return dL_dq, dL_dk, dL_dv\n",
    "\n",
    "class LinearLayer(Module):\n",
    "    def __init__(self, d_model=512, seq_len=100):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(d_model, d_model*2)\n",
    "        self.relu = ReLU()\n",
    "        self.fc2 = Linear(d_model*2, d_model)\n",
    "        self.norm = LayerNorm((d_model,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.residual = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        self.out = self.norm(x + self.residual)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        # Gradient of the normalization layer\n",
    "        dL_dnorm = self.norm.backward(dL_dy)\n",
    "\n",
    "        # Split the gradient at the addition operation\n",
    "        dL_dresidual = dL_dnorm  # Gradient through the residual connection\n",
    "        dL_dfc2_input = dL_dnorm  # Gradient through the output of fc2\n",
    "\n",
    "        # Gradient through the second linear layer\n",
    "        dL_dfc2 = self.fc2.backward(dL_dfc2_input)\n",
    "\n",
    "        # Gradient through the ReLU activation\n",
    "        dL_drelu = self.relu.backward(dL_dfc2)\n",
    "\n",
    "        # Gradient through the first linear layer\n",
    "        dL_dfc1 = self.fc1.backward(dL_drelu)\n",
    "\n",
    "        # Combine gradients from the residual and the main path\n",
    "        dL_dx = dL_dfc1 + dL_dresidual\n",
    "        \n",
    "        return dL_dx\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = np.triu(np.ones((size, size)), k=1)  # Upper triangular matrix with a shift\n",
    "    return mask != 1  # Convert to boolean mask\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    mask = (seq != 0)\n",
    "    return mask[:, np.newaxis,:, np.newaxis]\n",
    "\n",
    "def shift_right(x):\n",
    "    zero_col = np.zeros((x.shape[0], 1, x.shape[2]))  # Shape (batch_size, 1, d_model)\n",
    "    return np.concatenate([zero_col, x[:, :-1, :]], axis=1)\n",
    "\n",
    "class TransformerDecoder(Module):\n",
    "    def __init__(self, vocab_size=1000, d_model=512, num_heads=8, seq_len=10):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.input_embedding = Embedding(vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(seq_len, d_model)\n",
    "        self.masked_multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.linear_layer = LinearLayer(d_model, seq_len)\n",
    "        self.final_linear = Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x, k, v):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "        padding_mask = create_padding_mask(x)\n",
    "\n",
    "        pos = np.tile(np.arange(seq_len), (batch_size, 1))\n",
    "        x = self.input_embedding(x)\n",
    "        x = shift_right(x)\n",
    "        x += self.positional_embedding(pos)\n",
    "        \n",
    "        x = self.masked_multi_head_attention(x, x, x, look_ahead_mask[np.newaxis, np.newaxis, :, :])\n",
    "\n",
    "        x = self.multi_head_attention(x, k, v, padding_mask)\n",
    "        \n",
    "        x = self.linear_layer(x)\n",
    "        \n",
    "        logits = self.final_linear(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        # Backpropagate through the softmax and final linear layer\n",
    "        # dL_dlogits = self.softmax.backward(dL_dy)\n",
    "        dL_dlinear = self.final_linear.backward(dL_dy)\n",
    "        \n",
    "        # Backpropagate through the linear layer\n",
    "        dL_dlinear_layer = self.linear_layer.backward(dL_dlinear)\n",
    "        \n",
    "        # Split the gradients for the multi-head attention\n",
    "        dL_dmh_attention = dL_dlinear_layer\n",
    "        \n",
    "        # Backpropagate through the multi-head attention with encoder output\n",
    "        dL_dmh_attention, dL_dk, dL_dv = self.multi_head_attention.backward(dL_dmh_attention)\n",
    "\n",
    "        dL_dmh_self_attention, _, _ = self.masked_multi_head_attention.backward(dL_dmh_attention)\n",
    "\n",
    "        dL_dx = dL_dmh_self_attention\n",
    "        \n",
    "        return dL_dx, dL_dk, dL_dv\n",
    "\n",
    "\n",
    "class TransformerEncoder(Module):\n",
    "    def __init__(self, vocab_size=1000, d_model=512, num_heads=8, seq_len=10):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_embedding = Embedding(vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(seq_len, d_model)\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.linear_layer = LinearLayer(d_model, seq_len)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        pos = np.tile(np.arange(seq_len), (batch_size, 1))\n",
    "        padding_mask = create_padding_mask(x)\n",
    "        x = self.input_embedding(x) * np.sqrt(self.d_model)  # Scale embedding\n",
    "        x += self.positional_embedding(pos)\n",
    "\n",
    "        x = self.multi_head_attention(x, x, x, padding_mask)\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        # Backpropagate through the linear layer\n",
    "        dL_dlinear = self.linear_layer.backward(dL_dy)\n",
    "        \n",
    "        # Backpropagate through multi-head attention\n",
    "        dL_dattn_q, dL_dattn_k, dL_dattn_v = self.multi_head_attention.backward(dL_dlinear)\n",
    "        \n",
    "        dL_dx = dL_dattn_q\n",
    "        return dL_dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "Transformer Encoder test passed!\n",
      "(2, 6) (2, 5, 4)\n",
      "[[[0.12798767 0.05910522 0.07804094 0.03228785 0.10219736 0.04218396\n",
      "   0.12445106 0.05567584 0.05998418 0.15124005 0.01295072 0.1094877\n",
      "   0.04440743]\n",
      "  [0.1259877  0.05822148 0.08097165 0.03275435 0.10289431 0.04067557\n",
      "   0.12213755 0.05612124 0.06259635 0.14920348 0.01277771 0.11301733\n",
      "   0.04264127]\n",
      "  [0.12506706 0.05780112 0.08246547 0.03305832 0.10317893 0.03989981\n",
      "   0.12087075 0.05634645 0.0638154  0.14795    0.01270058 0.11505155\n",
      "   0.04179459]\n",
      "  [0.12383291 0.05768478 0.08216824 0.03233417 0.10352302 0.04062867\n",
      "   0.12201166 0.05630662 0.06509084 0.15017779 0.01273842 0.11158774\n",
      "   0.04191516]\n",
      "  [0.12699205 0.05802258 0.08274382 0.03419007 0.10256672 0.03889228\n",
      "   0.11917844 0.05638582 0.06177453 0.1445815  0.01266806 0.12029779\n",
      "   0.04170635]\n",
      "  [0.12392952 0.05784103 0.08142724 0.0320299  0.10347182 0.04115768\n",
      "   0.12284741 0.05619519 0.06484192 0.15127346 0.01278292 0.10988206\n",
      "   0.04231986]]\n",
      "\n",
      " [[0.12798767 0.05910522 0.07804094 0.03228785 0.10219736 0.04218396\n",
      "   0.12445106 0.05567584 0.05998418 0.15124005 0.01295072 0.1094877\n",
      "   0.04440743]\n",
      "  [0.12535882 0.05803755 0.08145351 0.0326936  0.10308425 0.04055821\n",
      "   0.12194306 0.05619462 0.06333993 0.14927325 0.01275653 0.11295327\n",
      "   0.0423534 ]\n",
      "  [0.12660351 0.05807899 0.08215829 0.03366541 0.10271208 0.03950444\n",
      "   0.12022375 0.05629874 0.06212819 0.14624003 0.01270166 0.11767459\n",
      "   0.04201033]\n",
      "  [0.12548392 0.05770697 0.0832713  0.03368649 0.10303914 0.03911448\n",
      "   0.1195638  0.05646477 0.06346826 0.14591336 0.01265127 0.11825819\n",
      "   0.04137806]\n",
      "  [0.12590586 0.05772066 0.08351599 0.0340399  0.10289353 0.03875369\n",
      "   0.11894719 0.05650008 0.06303004 0.14482997 0.01263496 0.11996669\n",
      "   0.04126143]\n",
      "  [0.1245379  0.05783014 0.08192549 0.0325404  0.10332446 0.04052863\n",
      "   0.12187696 0.05626754 0.06429295 0.14961903 0.01274054 0.11244719\n",
      "   0.04206878]]]\n",
      "Transformer Decoder test passed!\n"
     ]
    }
   ],
   "source": [
    "vocab_size1 = 12\n",
    "vocab_size2 = 13\n",
    "seq_len1 = 5\n",
    "seq_len2 = 6\n",
    "\n",
    "d_model = 4\n",
    "num_heads = 4\n",
    "batch_size = 2\n",
    "\n",
    "softmax = Softmax()\n",
    "\n",
    "encoder = TransformerEncoder(vocab_size1, d_model, num_heads, seq_len1)\n",
    "\n",
    "# Create a sample input (batch_size, seq_len)\n",
    "sample_input = np.random.randint(0, vocab_size1, (batch_size, seq_len1))\n",
    "sample_input = np.zeros((batch_size, seq_len1), dtype=np.int16)\n",
    "print(sample_input.shape)\n",
    "# Forward pass\n",
    "encoder_output = encoder(sample_input)\n",
    "\n",
    "# Check the encoder_output shape\n",
    "assert encoder_output.shape == (batch_size, seq_len1, d_model), f\"Output shape mismatch: expected {(batch_size, seq_len1, d_model)}, got {encoder_output.shape}\"\n",
    "\n",
    "print(\"Transformer Encoder test passed!\")\n",
    "\n",
    "# Initialize the decoder\n",
    "decoder = TransformerDecoder(vocab_size2, d_model, num_heads, seq_len2)\n",
    "\n",
    "# Create a sample input for the decoder (batch_size, seq_len)\n",
    "sample_input = np.random.randint(0, vocab_size2, (batch_size, seq_len2))\n",
    "print(sample_input.shape, encoder_output.shape)\n",
    "# Forward pass through the decoder\n",
    "output = decoder(sample_input, encoder_output, encoder_output)\n",
    "\n",
    "softmax_output = softmax(output.squeeze())\n",
    "\n",
    "print(softmax_output)\n",
    "\n",
    "# Check the output shape\n",
    "assert output.shape == (batch_size, seq_len2, vocab_size2), f\"Output shape mismatch: expected {(batch_size, seq_len2, vocab_size2)}, got {output.shape}\"\n",
    "\n",
    "print(\"Transformer Decoder test passed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_vocab, trg_vocab, encoder, decoder, max_len=25):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    softmax = Softmax()\n",
    "    tokens = [token.lower() for token in sentence.split()]\n",
    "    tokens = (\n",
    "        [src_vocab[\"<SOS>\"]]\n",
    "        + [src_vocab.get(token, src_vocab[\"<UNK>\"]) for token in tokens]\n",
    "        + [src_vocab[\"<EOS>\"]]\n",
    "    )\n",
    "\n",
    "    src_tensor = np.array(tokens).reshape(1, -1)\n",
    "    encoder_output = encoder(src_tensor)\n",
    "\n",
    "    trg_indexes = [trg_vocab[\"<SOS>\"]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = np.array([trg_indexes[-1]]).reshape(1,-1)\n",
    "        decoder_output = decoder(trg_tensor, encoder_output, encoder_output)\n",
    "        softmax_output = softmax(decoder_output.squeeze())\n",
    "        pred_token = softmax_output.argmax(0)\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_vocab[\"<EOS>\"]:\n",
    "            break\n",
    "\n",
    "    trg_tokens = [\n",
    "        list(trg_vocab.keys())[list(trg_vocab.values()).index(i)] for i in trg_indexes\n",
    "    ]\n",
    "\n",
    "    return trg_tokens[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder has 10637824 parameters\n",
      "decoder has 38867385 parameters\n",
      "[[   1  598  253  105 7174   43  242 4211    2]]\n",
      "Translation: kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien kirjoittamien\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 1/1000 [00:21<6:04:11, 21.87s/it, train_loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  598  253  105 7174   43  242 4211    2]]\n",
      "Translation: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 11/1000 [03:49<5:41:01, 20.69s/it, train_loss=2.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  598  253  105 7174   43  242 4211    2]]\n",
      "Translation: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "from jonigrad.utils import load_fi_en_translations\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = np.random.default_rng()  # create a random generator\n",
    "\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "BATCH_SIZE = 32\n",
    "ITERS = 1000\n",
    "LR = 0.1\n",
    "THRESHOLD = 1\n",
    "\n",
    "en_data, en_vocab, fi_data, fi_vocab = load_fi_en_translations(debug=False)\n",
    "\n",
    "SEQ_LEN_INPUT = en_data.shape[1]\n",
    "SEQ_LEN_OUTPUT = fi_data.shape[1]\n",
    "INPUT_VOCAB = len(en_vocab)\n",
    "OUTPUT_VOCAB = len(fi_vocab)\n",
    "\n",
    "encoder = TransformerEncoder(INPUT_VOCAB, D_MODEL, NUM_HEADS, SEQ_LEN_INPUT)\n",
    "decoder = TransformerDecoder(OUTPUT_VOCAB, D_MODEL, NUM_HEADS, SEQ_LEN_OUTPUT)\n",
    "\n",
    "\n",
    "print(f\"encoder has {encoder.parameter_count()} parameters\")\n",
    "print(f\"decoder has {decoder.parameter_count()} parameters\")\n",
    "\n",
    "loss_f = CrossEntropyLoss(ignore_index=0)\n",
    "losses = []\n",
    "\n",
    "\n",
    "sentence = \"how are you today i am good?\"\n",
    "translation = translate_sentence(sentence, en_vocab, fi_vocab, encoder, decoder)\n",
    "print(\"Translation:\", \" \".join(translation))\n",
    "\n",
    "pbar = tqdm(range(ITERS), desc=\"Training Progress\")\n",
    "for i in pbar:\n",
    "    ix = g.integers(low=0, high=en_data.shape[0], size=BATCH_SIZE)\n",
    "    Xb, Yb = en_data[ix], fi_data[ix]\n",
    "\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    encoder_output = encoder(Xb)\n",
    "    decoder_output = decoder(Yb, encoder_output, encoder_output)\n",
    "    one_hot_targs = np.eye(OUTPUT_VOCAB)[Yb].astype(np.float32)\n",
    "    loss = loss_f(decoder_output, one_hot_targs)\n",
    "\n",
    "    dL_dy = loss_f.backward()\n",
    "\n",
    "    dL_dx, dL_dk, dL_dv = decoder.backward(dL_dy)\n",
    "    dL_dx = encoder.backward(dL_dk)\n",
    "\n",
    "    decoder.clip_grad(THRESHOLD, BATCH_SIZE)\n",
    "    encoder.clip_grad(THRESHOLD, BATCH_SIZE)\n",
    "\n",
    "    encoder.step(LR)\n",
    "    decoder.step(LR)\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    pbar.set_postfix({\"train_loss\": loss.item()})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sentence = \"how are you today i am good?\"\n",
    "        translation = translate_sentence(sentence, en_vocab, fi_vocab, encoder, decoder)\n",
    "        print(\"Translation:\", \" \".join(translation))\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABGTUlEQVR4nO3deXiU1f3+8XsySSZ7AlkJBLIAhgAqCCiggAooAhWwdakb2NZ+FReqtEUtKioiWi2t1rX9CS5UaStYsS6AgqIiq1QFCRgCAcwGIfs68/z+SDIwQiCETJ5Z3q/rmkvzzJJPFpibcz7nHIthGIYAAAC8UIDZBQAAALQVQQYAAHgtggwAAPBaBBkAAOC1CDIAAMBrEWQAAIDXIsgAAACvRZABAABeiyADAAC8FkEG8GBTp05Vampqm5774IMPymKxtG9B8BqjRo3SqFGjzC4DcDuCDNAGFoulVbfVq1ebXaoppk6dqoiICLPLaBXDMPTqq69qxIgRiomJUVhYmPr376+HHnpIlZWVZpfnlJub2+rfu9zcXLPLBTqMhbOWgFP32muvuXz8yiuvaMWKFXr11Vddro8ZM0aJiYlt/jz19fVyOByy2Wyn/NyGhgY1NDQoJCSkzZ+/raZOnap//etfqqio6PDPfSrsdrt+/vOfa8mSJbrgggs0ZcoUhYWF6dNPP9XixYuVlZWllStXntbPsL1UVlZq6dKlLteefPJJ7du3T3/6059crk+ePFlBQUGSpODg4A6rETADQQZoB7fddpv++te/6mR/nKqqqhQWFtZBVZnHW4LMvHnzdO+992rmzJl64oknXO575513NGnSJI0dO1bvvfdeh9bV2t+TCRMm6JtvvmEEBn6NqSXATUaNGqV+/fpp06ZNGjFihMLCwnTvvfdKkt5++22NHz9eycnJstlsysjI0MMPPyy73e7yGj/ukWmeXvjjH/+oF198URkZGbLZbBo8eLA2bNjg8tzj9chYLBbddtttWrZsmfr16yebzaa+ffvq/fffP6b+1atXa9CgQQoJCVFGRoZeeOGFdu+7+ec//6lzzjlHoaGhiouL03XXXaf9+/e7PCY/P1/Tpk1Tt27dZLPZ1KVLF11++eUub94bN27UJZdcori4OIWGhiotLU033XTTCT93dXW1nnjiCfXu3Vvz5s075v6JEyfqxhtv1Pvvv69169ZJagwO6enpx329oUOHatCgQS7XXnvtNefX17lzZ1199dXKy8tzecyJfk9Ox497ZFavXi2LxaIlS5Zozpw56tq1qyIjI/XTn/5UpaWlqq2t1YwZM5SQkKCIiAhNmzZNtbW1x7xua74moCMFml0A4MsOHjyocePG6eqrr9Z1113nnKJYuHChIiIidNdddykiIkIfffSR7r//fpWVlR0zMnA8ixcvVnl5uX7961/LYrHo8ccf15QpU5STk+OcUmjJ2rVr9dZbb+nWW29VZGSk/vKXv+iKK67Q3r17FRsbK0nasmWLLr30UnXp0kVz5syR3W7XQw89pPj4+NP/pjRZuHChpk2bpsGDB2vevHkqKCjQn//8Z3322WfasmWLYmJiJElXXHGFvv32W91+++1KTU1VYWGhVqxYob179zo/Hjt2rOLj4zVr1izFxMQoNzdXb7311km/DyUlJbrzzjsVGHj8vwpvuOEGvfzyy1q+fLnOO+88XXXVVbrhhhu0YcMGDR482Pm4PXv2aN26dS4/u7lz52r27Nm68sor9ctf/lJFRUV6+umnNWLECJevT2r598Qd5s2bp9DQUM2aNUu7du3S008/raCgIAUEBKikpEQPPvig1q1bp4ULFyotLU33339/m74moMMYAE7b9OnTjR//cRo5cqQhyXj++eePeXxVVdUx1379618bYWFhRk1NjfPajTfeaPTo0cP58e7duw1JRmxsrHHo0CHn9bffftuQZLzzzjvOaw888MAxNUkygoODjV27djmvbd261ZBkPP30085rEydONMLCwoz9+/c7r+3cudMIDAw85jWP58YbbzTCw8NbvL+urs5ISEgw+vXrZ1RXVzuvL1++3JBk3H///YZhGEZJSYkhyXjiiSdafK2lS5cakowNGzactK6jLViwwJBkLF26tMXHHDp0yJBkTJkyxTAMwygtLTVsNptx9913uzzu8ccfNywWi7Fnzx7DMAwjNzfXsFqtxty5c10e9/XXXxuBgYEu10/0e3Iy48ePd/n9ONrIkSONkSNHOj/++OOPDUlGv379jLq6Ouf1a665xrBYLMa4ceNcnj906FCX1z6VrwnoSEwtAW5ks9k0bdq0Y66HhoY6/7+8vFzFxcW64IILVFVVpe++++6kr3vVVVepU6dOzo8vuOACSVJOTs5Jnzt69GhlZGQ4Pz7zzDMVFRXlfK7dbtfKlSs1adIkJScnOx/Xs2dPjRs37qSv3xobN25UYWGhbr31Vpdm5PHjxyszM1PvvvuupMbvU3BwsFavXq2SkpLjvlbzKMDy5ctVX1/f6hrKy8slSZGRkS0+pvm+srIySVJUVJTGjRunJUuWuPRDvfnmmzrvvPPUvXt3SdJbb70lh8OhK6+8UsXFxc5bUlKSevXqpY8//tjl87T0e+ION9xwg8uo3bnnnivDMI6Zijv33HOVl5enhoYGSaf+NQEdhSADuFHXrl2Pu2rk22+/1eTJkxUdHa2oqCjFx8fruuuukySVlpae9HWb3zCbNYealt7sT/Tc5uc3P7ewsFDV1dXq2bPnMY873rW22LNnjyTpjDPOOOa+zMxM5/02m03z58/Xe++9p8TERI0YMUKPP/648vPznY8fOXKkrrjiCs2ZM0dxcXG6/PLL9fLLLx+3v+NozSGlOdAcz/HCzlVXXaW8vDx98cUXkqTvv/9emzZt0lVXXeV8zM6dO2UYhnr16qX4+HiX2/bt21VYWOjyeVr6PXGHH//8o6OjJUkpKSnHXHc4HM7fx1P9moCOQo8M4EZHj7w0O3z4sEaOHKmoqCg99NBDysjIUEhIiDZv3qzf//73cjgcJ31dq9V63OtGKxYhns5zzTBjxgxNnDhRy5Yt0wcffKDZs2dr3rx5+uijjzRgwABZLBb961//0rp16/TOO+/ogw8+0E033aQnn3xS69ata3E/mz59+kiS/ve//2nSpEnHfcz//vc/SVJWVpbz2sSJExUWFqYlS5Zo2LBhWrJkiQICAvSzn/3M+RiHwyGLxaL33nvvuN/vH9d0vN8Td2np53+y34tT/ZqAjkKQATrY6tWrdfDgQb311lsaMWKE8/ru3btNrOqIhIQEhYSEaNeuXcfcd7xrbdGjRw9J0o4dO3TRRRe53Ldjxw7n/c0yMjJ099136+6779bOnTt19tln68knn3TZz+e8887Teeedp7lz52rx4sW69tpr9cYbb+iXv/zlcWs4//zzFRMTo8WLF+u+++477pvzK6+8IqlxtVKz8PBwTZgwQf/85z/11FNP6c0339QFF1zgMg2XkZEhwzCUlpam3r17n+J3xzP54tcE38DUEtDBmt8wjx4Bqaur07PPPmtWSS6sVqtGjx6tZcuW6cCBA87ru3btarf9VAYNGqSEhAQ9//zzLlNA7733nrZv367x48dLatxPpaamxuW5GRkZioyMdD6vpKTkmNGks88+W5JOOL0UFhammTNnaseOHbrvvvuOuf/dd9/VwoULdckll+i8885zue+qq67SgQMH9Le//U1bt251mVaSpClTpshqtWrOnDnH1GYYhg4ePNhiXZ7KF78m+AZGZIAONmzYMHXq1Ek33nij7rjjDlksFr366qseNbXz4IMP6sMPP9Tw4cN1yy23yG6365lnnlG/fv301Vdfteo16uvr9cgjjxxzvXPnzrr11ls1f/58TZs2TSNHjtQ111zjXH6dmpqq3/zmN5Kk7OxsXXzxxbryyiuVlZWlwMBALV26VAUFBbr66qslSYsWLdKzzz6ryZMnKyMjQ+Xl5XrppZcUFRWlyy677IQ1zpo1S1u2bNH8+fP1xRdf6IorrlBoaKjWrl2r1157TX369NGiRYuOed5ll12myMhIzZw5U1arVVdccYXL/RkZGXrkkUd0zz33KDc3V5MmTVJkZKR2796tpUuX6uabb9bMmTNb9X30FL74NcE3EGSADhYbG6vly5fr7rvv1h/+8Ad16tRJ1113nS6++GJdcsklZpcnSTrnnHP03nvvaebMmZo9e7ZSUlL00EMPafv27a1aVSU1jjLNnj37mOsZGRm69dZbNXXqVIWFhemxxx7T73//e4WHh2vy5MmaP3++cyVSSkqKrrnmGq1atUqvvvqqAgMDlZmZqSVLljjDw8iRI7V+/Xq98cYbKigoUHR0tIYMGaLXX39daWlpJ6zRarVqyZIleuWVV/S3v/1Ns2fPVl1dnTIyMvTAAw/o7rvvVnh4+DHPCwkJ0U9+8hO9/vrrGj16tBISEo55zKxZs9S7d2/96U9/0pw5c5xfz9ixY/WTn/ykVd9DT+OLXxO8H0cUAGi1SZMm6dtvv9XOnTvNLgUAJNEjA6AF1dXVLh/v3LlT//3vf122vQcAszEiA+C4unTpoqlTpyo9PV179uzRc889p9raWm3ZskW9evUyuzwAkESPDIAWXHrppfrHP/6h/Px82Ww2DR06VI8++ighBoBHYUQGAAB4LXpkAACA1yLIAAAAr+XzPTIOh0MHDhxQZGSkLBaL2eUAAIBWMAxD5eXlSk5OVkBAy+MuPh9kDhw4cMyprgAAwDvk5eWpW7duLd7v80EmMjJSUuM3IioqyuRqAABAa5SVlSklJcX5Pt4Snw8yzdNJUVFRBBkAALzMydpCaPYFAABeiyADAAC8FkEGAAB4LYIMAADwWgQZAADgtQgyAADAaxFkAACA1yLIAAAAr0WQAQAAXosgAwAAvBZBBgAAeC2CDAAA8FoEmTZqsDuUW1ypgxW1ZpcCAIDfIsi00Z1vfqVRf1ytZV8dMLsUAAD8FkGmjVJjwyRJu4srTK4EAAD/RZBpo7S4CEnS7uJKkysBAMB/EWTaKC0uXJK0u4ggAwCAWQgybZTeFGQOlNaous5ucjUAAPgngkwbdQoPVqewIElMLwEAYBaCzGlwTi8RZAAAMAVB5jQcafhl5RIAAGYgyJyG9PjGEZkcRmQAADAFQeY0MLUEAIC5CDKngSADAIC5CDKnoTnIHK6q16HKOpOrAQDA/xBkTkNIkFVdY0Il0fALAIAZCDKnqXlUJocdfgEA6HAEmdNEnwwAAOYhyJwmggwAAOYhyJymtHiCDAAAZiHInKYM5+6+lXI4DJOrAQDAvxBkTlPXTqEKslpU2+DQgdJqs8sBAMCvEGROkzXAoh6xTC8BAGAGgkw7oOEXAABzEGTaQTp7yQAAYApTg8wnn3yiiRMnKjk5WRaLRcuWLXO53zAM3X///erSpYtCQ0M1evRo7dy505xiT4ARGQAAzGFqkKmsrNRZZ52lv/71r8e9//HHH9df/vIXPf/88/ryyy8VHh6uSy65RDU1NR1c6YmlxzeuXMrhmAIAADpUoJmffNy4cRo3btxx7zMMQwsWLNAf/vAHXX755ZKkV155RYmJiVq2bJmuvvrqjiz1hJpHZPaVVKu2wS5boNXkigAA8A8e2yOze/du5efna/To0c5r0dHROvfcc/XFF1+0+Lza2lqVlZW53NwtLiJYkbZAGYa092CV2z8fAABo5LFBJj8/X5KUmJjocj0xMdF53/HMmzdP0dHRzltKSopb65Qki8Xi3OE3hz4ZAAA6jMcGmba65557VFpa6rzl5eV1yOel4RcAgI7nsUEmKSlJklRQUOByvaCgwHnf8dhsNkVFRbncOkJ601EFOUU0/AIA0FE8NsikpaUpKSlJq1atcl4rKyvTl19+qaFDh5pY2fFxeCQAAB3P1FVLFRUV2rVrl/Pj3bt366uvvlLnzp3VvXt3zZgxQ4888oh69eqltLQ0zZ49W8nJyZo0aZJ5RbcgnaklAAA6nKlBZuPGjbrwwgudH991112SpBtvvFELFy7U7373O1VWVurmm2/W4cOHdf755+v9999XSEiIWSW3KLUpyBRX1Km0ul7RoUEmVwQAgO+zGIZhmF2EO5WVlSk6OlqlpaVu75cZMnelCstr9fb04TorJcatnwsAAF/W2vdvj+2R8UasXAIAoGMRZNqR86gCVi4BANAhCDLtyHkKNiMyAAB0CIJMO2JqCQCAjkWQaUdH7yXj4z3UAAB4BIJMO0rpFCZrgEVVdXYVlteaXQ4AAD6PINOOggMDlNIpVJKUU8T0EgAA7kaQaWfOlUvFrFwCAMDdCDLtzNnwy4gMAABuR5BpZ6xcAgCg4xBk2hmHRwIA0HEIMu2seQn23kNVqrc7TK4GAADfRpBpZ4mRIQoNsqrBYWhfSbXZ5QAA4NMIMu0sIMDi7JPhzCUAANyLIOMGR+/wCwAA3Icg4wYcHgkAQMcgyLgBe8kAANAxCDJuwF4yAAB0DIKMG6THNR5TkF9Wo8raBpOrAQDAdxFk3CA6LEix4cGSGJUBAMCdCDJuwvQSAADuR5BxE4IMAADuR5BxE/aSAQDA/QgybsJeMgAAuB9Bxk3S4xtXLuUUVcgwDJOrAQDANxFk3KR75zBZLFJ5TYMOVtaZXQ4AAD6JIOMmIUFWdY0JlUSfDAAA7kKQcSOOKgAAwL0IMm5Ewy8AAO5FkHGjI3vJVJhcCQAAvokg40ZHVi4xIgMAgDsQZNyoeURmz8Eq2R0swQYAoL0RZNwoOSZUwYEBqrM7dOBwtdnlAADgcwgybmQNsCg1NkwSDb8AALgDQcbNjizBpuEXAID2RpBxs7S4xoZfNsUDAKD9EWTcLD2evWQAAHAXgoybOTfFYwk2AADtjiDjZs09MgdKq1VTbze5GgAAfAtBxs06hwcrKiRQhtG4nwwAAGg/BBk3s1gsSotvbvhl5RIAAO2JINMBODwSAAD3IMh0ABp+AQBwD4JMB0iLbz4FmyADAEB7Ish0AOfuvgQZAADaFUGmA6TGNgaZQ5V1OlxVZ3I1AAD4DoJMBwi3BSopKkQSozIAALQngkwHSaPhFwCAdkeQ6SDpNPwCANDuCDIdhIZfAADaH0Gmg3AKNgAA7Y8g00HS4hqPKcgtrpTDYZhcDQAAvoEg00G6dQpVYIBF1fV2FZTXmF0OAAA+gSDTQYKsAeoeGyaJlUsAALQXgkwH4vBIAADaF0GmAzlXLjEiAwBAuyDIdKDmht/dxRUmVwIAgG8gyHQg9pIBAKB9EWQ6UPNeMnkl1aprcJhcDQAA3o8g04ESIm0KD7bK7jC091CV2eUAAOD1CDIdyGKxKI0zlwAAaDcEmQ5Gwy8AAO2HINPBaPgFAKD9eHSQsdvtmj17ttLS0hQaGqqMjAw9/PDDMgzvPavIuSkee8kAAHDaAs0u4ETmz5+v5557TosWLVLfvn21ceNGTZs2TdHR0brjjjvMLq9NGJEBAKD9eHSQ+fzzz3X55Zdr/PjxkqTU1FT94x//0Pr1602urO2am30Ly2tVXlOvyJAgkysCAMB7efTU0rBhw7Rq1SplZ2dLkrZu3aq1a9dq3LhxJlfWdlEhQYqLsEmScotZgg0AwOnw6BGZWbNmqaysTJmZmbJarbLb7Zo7d66uvfbaFp9TW1ur2tpa58dlZWUdUeopSY8LV3FFrXKKK9S/W7TZ5QAA4LU8ekRmyZIlev3117V48WJt3rxZixYt0h//+EctWrSoxefMmzdP0dHRzltKSkoHVtw69MkAANA+PDrI/Pa3v9WsWbN09dVXq3///rr++uv1m9/8RvPmzWvxOffcc49KS0udt7y8vA6suHXYFA8AgPbh0VNLVVVVCghwzVpWq1UOR8vnFNlsNtlsNneXdlrSWIINAEC78OggM3HiRM2dO1fdu3dX3759tWXLFj311FO66aabzC7ttGQcNSJjGIYsFovJFQEA4J08Osg8/fTTmj17tm699VYVFhYqOTlZv/71r3X//febXdppSekcpgCLVFHboKKKWiVEhphdEgAAXsmjg0xkZKQWLFigBQsWmF1Ku7IFWtWtU5j2HqrS7qJKggwAAG3k0c2+voyVSwAAnD6CjEkIMgAAnD6CjEnSmxp+v2flEgAAbUaQMUl6XIQkaXdxhcmVAADgvQgyJmneFG/voSo12FveFwcAALSMIGOSLlEhsgUGqN5uaP/harPLAQDAKxFkTBIQYDmywy8NvwAAtAlBxkTOlUs0/AIA0CYEGRMdGZGh4RcAgLYgyJgoPb555RIjMgAAtAVBxkRMLQEAcHoIMiZKbwoyB0prVF1nN7kaAAC8D0HGRJ3CgxUTFiRJyj3IqAwAAKeKIGMyzlwCAKDtCDImaz6qIKeIlUsAAJwqgozJmg+PZFM8AABOHUHGZEwtAQDQdgQZkxFkAABoO4KMyVJjG4PM4ap6lVTWmVwNAADehSBjstBgq5KjQyTRJwMAwKkiyHiA5qMKWLkEAMCpIch4APpkAABoG4KMByDIAADQNgQZD5AWT5ABAKAtCDIeIP2oERmHwzC5GgAAvAdBxgN0jQlVkNWi2gaHDpRWm10OAABegyDjAQKtAeoRy/QSAACniiDjIWj4BQDg1BFkPERzn0xOEUEGAIDWIsh4CEZkAAA4dQQZD0GQAQDg1BFkPETzXjL7SqpU22A3uRoAALwDQcZDxEfYFGkLlMOQ9h6sMrscAAC8AkHGQ1gsFueoDKdgAwDQOgQZD0KfDAAAp4Yg40GcQYYl2AAAtApBxoMwIgMAwKkhyHiQ9LgISVJOcYXJlQAA4B0IMh6kudm3uKJOpdX1JlcDAIDnI8h4kAhboBIibZKkXKaXAAA4KYKMh6FPBgCA1iPIeJh09pIBAKDVCDIehhEZAABajyDjYZwrl4pYuQQAwMkQZDxM88ql3cWVMgzD5GoAAPBsBBkPk9IpTNYAi6rq7CosrzW7HAAAPBpBxsMEBwYopVOoJCmHowoAADghgowHouEXAIDWIch4oDQafgEAaBWCjAdKj2dEBgCA1mhTkMnLy9O+ffucH69fv14zZszQiy++2G6F+bN0ppYAAGiVNgWZn//85/r4448lSfn5+RozZozWr1+v++67Tw899FC7FuiPmpdg7z1UpXq7w+RqAADwXG0KMt98842GDBkiSVqyZIn69eunzz//XK+//roWLlzYnvX5pcTIEIUGWdXgMLSvpNrscgAA8FhtCjL19fWy2RpPaV65cqV+8pOfSJIyMzP1ww8/tF91fiogwKJU5/QSDb8AALSkTUGmb9++ev755/Xpp59qxYoVuvTSSyVJBw4cUGxsbLsW6K+a+2TYSwYAgJa1KcjMnz9fL7zwgkaNGqVrrrlGZ511liTpP//5j3PKCaeHU7ABADi5wLY8adSoUSouLlZZWZk6derkvH7zzTcrLCys3YrzZ85N8RiRAQCgRW0akamurlZtba0zxOzZs0cLFizQjh07lJCQ0K4F+it29wUA4OTaFGQuv/xyvfLKK5Kkw4cP69xzz9WTTz6pSZMm6bnnnmvXAv1Vc5DJL6tRZW2DydUAAOCZ2hRkNm/erAsuuECS9K9//UuJiYnas2ePXnnlFf3lL39p1wL9VUxYsDqHB0uScg8yKgMAwPG0KchUVVUpMjJSkvThhx9qypQpCggI0Hnnnac9e/a0a4H+LI2VSwAAnFCbgkzPnj21bNky5eXl6YMPPtDYsWMlSYWFhYqKimrXAv0ZRxUAAHBibQoy999/v2bOnKnU1FQNGTJEQ4cOldQ4OjNgwIB2LdCfpXF4JAAAJ9Sm5dc//elPdf755+uHH35w7iEjSRdffLEmT57cbsX5O+emeAQZAACOq00jMpKUlJSkAQMG6MCBA86TsIcMGaLMzMx2K06S9u/fr+uuu06xsbEKDQ1V//79tXHjxnb9HJ4qLS5CkrS7qEKGYZhcDQAAnqdNQcbhcOihhx5SdHS0evTooR49eigmJkYPP/ywHI72O625pKREw4cPV1BQkN577z1t27ZNTz75pMsmfL6sR2yYLBaprKZBhyrrzC4HAACP06appfvuu09///vf9dhjj2n48OGSpLVr1+rBBx9UTU2N5s6d2y7FzZ8/XykpKXr55Zed19LS0trltb1BSJBVydGh2n+4WjnFlYqNsJldEgAAHqVNIzKLFi3S3/72N91yyy0688wzdeaZZ+rWW2/VSy+9pIULF7Zbcf/5z380aNAg/exnP1NCQoIGDBigl156qd1e3xs0n7nEUQUAAByrTUHm0KFDx+2FyczM1KFDh067qGY5OTl67rnn1KtXL33wwQe65ZZbdMcdd2jRokUtPqe2tlZlZWUuN29Gwy8AAC1rU5A566yz9Mwzzxxz/ZlnntGZZ5552kU1czgcGjhwoB599FENGDBAN998s371q1/p+eefb/E58+bNU3R0tPOWkpLSbvWY4ciZSxUmVwIAgOdpU4/M448/rvHjx2vlypXOPWS++OIL5eXl6b///W+7FdelSxdlZWW5XOvTp4/+/e9/t/ice+65R3fddZfz47KyMq8OM2nxTSuXGJEBAOAYbRqRGTlypLKzszV58mQdPnxYhw8f1pQpU/Ttt9/q1Vdfbbfihg8frh07drhcy87OVo8ePVp8js1mU1RUlMvNmzVPLeUerJLdwRJsAACOZjHacYOSrVu3auDAgbLb7e3yehs2bNCwYcM0Z84cXXnllVq/fr1+9atf6cUXX9S1117bqtcoKytTdHS0SktLvTLU2B2G+tz/vuoaHPr0dxcqpXOY2SUBAOB2rX3/bvOGeB1h8ODBWrp0qf7xj3+oX79+evjhh7VgwYJWhxhfYA2wKDW2MbzQ8AsAgKs29ch0pAkTJmjChAlml2GqtLhwZRdUaHdRhUb2jje7HAAAPIZHj8igkfOoAkZkAABwcUojMlOmTDnh/YcPHz6dWtAC9pIBAOD4TinIREdHn/T+G2644bQKwrHSmnb3zWF3XwAAXJxSkDn6zCN0nOYRmQOl1aqptyskyGpyRQAAeAZ6ZLxA5/BgRYUEyjCkPQerzC4HAACPQZDxAhaL5agdfjmqAACAZgQZL0HDLwAAxyLIeAnn4ZE0/AIA4ESQ8RJpjMgAAHAMgoyXSG9ags2meAAAHEGQ8RKpsY1B5lBlnQ5X1ZlcDQAAnoEg4yXCbYFKigqRxKgMAADNCDJexNnwS5ABAEASQcarpNEnAwCAC4KMF3HuJcMSbAAAJBFkvErzyiWWYAMA0Igg40XS4hqPKcgtrpTDYZhcDQAA5iPIeJFunUIVGGBRdb1dBeU1ZpcDAIDpCDJeJMgaoO6dwyRxVAEAABJBxutwVAEAAEcQZLxMGiuXAABwIsh4mfT4xobf3cUVJlcCAID5CDJeht19AQA4giDjZZr3kskrqVZdg8PkagAAMBdBxsskRNoUFmyV3WEor6TK7HIAADAVQcbLWCwWGn4BAGhCkPFCR/pkaPgFAPg3gowXOrJyiREZAIB/I8h4IU7BBgCgEUHGC7EEGwCARgQZL5TaFGQKy2tVUdtgcjUAAJiHIOOFokODFBcRLInDIwEA/o0g46XS4xobfnNYuQQA8GMEGS9FnwwAAAQZr5UWT5ABAIAg46UYkQEAgCDjtZr3ktldVCnDMEyuBgAAcxBkvFT32DAFWKTy2gYVVdSaXQ4AAKYgyHgpW6BV3TqFSWIJNgDAfxFkvBh9MgAAf0eQ8WIEGQCAvyPIeLH0piXYOQQZAICfIsh4MUZkAAD+jiDjxZqDzJ6DlWqwO0yuBgCAjkeQ8WLJ0aGyBQao3m5o/+Fqs8sBAKDDEWS8WECAxTkqQ58MAMAfEWS8XNpRO/wCAOBvCDJejoZfAIA/I8h4OYIMAMCfEWS8nHMvmaIKkysBAKDjEWS8XHpchCTpQGmNquvsJlcDAEDHIsh4uU7hwYoJC5Ik5R5kegkA4F8IMj6APhkAgL8iyPgAggwAwF8RZHxAelOQ+Z6GXwCAnyHI+IC0poZfRmQAAP6GIOMDmpdgE2QAAP6GIOMDUmMbg8zhqnqVVNaZXA0AAB2HIOMDQoOtSo4OkcThkQAA/0KQ8RFpTC8BAPwQQcZHNC/B5qgCAIA/Icj4iHRWLgEA/BBBxkcwtQQA8EcEGR+RftTuvg6HYXI1AAB0DK8KMo899pgsFotmzJhhdikep2tMqIKsFtU2OPRDWY3Z5QAA0CG8Jshs2LBBL7zwgs4880yzS/FIgdYAde8cJknaXcT0EgDAP3hFkKmoqNC1116rl156SZ06dTK7HI/VfFRBTjErlwAA/sErgsz06dM1fvx4jR49+qSPra2tVVlZmcvNX2TENy/BZkQGAOAfAs0u4GTeeOMNbd68WRs2bGjV4+fNm6c5c+a4uSrPlBbHyiUAgH/x6BGZvLw83XnnnXr99dcVEhLSqufcc889Ki0tdd7y8vLcXKXnIMgAAPyNR4/IbNq0SYWFhRo4cKDzmt1u1yeffKJnnnlGtbW1slqtLs+x2Wyy2WwdXapHaN5LZl9JlWob7LIFWk/yDAAAvJtHB5mLL75YX3/9tcu1adOmKTMzU7///e+PCTH+Lj7CpghboCpqG5R3qEo9EyLNLgkAALfy6CATGRmpfv36uVwLDw9XbGzsMdchWSwWpcWF6+v9pfq+qJIgAwDweR7dI4NTl85RBQAAP+LRIzLHs3r1arNL8GjOhl+WYAMA/AAjMj6GlUsAAH9CkPEx6c7dfQkyAADfR5DxMalxjectFVfUqqym3uRqAABwL4KMj4kMCVJ8ZOM+OvTJAAB8HUHGB6XTJwMA8BMEGR/UvASbPhkAgK8jyPggVi4BAPwFQcYHpTWtXNpdXGFyJQAAuBdBxgcdvSmeYRgmVwMAgPsQZHxQ985hsgZYVFlnV2F5rdnlAADgNgQZHxQcGKCUTqGSpByWYAMAfBhBxkfR8AsA8AcEGR9Fwy8AwB8QZHxUWjwjMgAA30eQ8VHNu/vSIwMA8GUEGR/V3COz91CV6u0Ok6sBAMA9CDI+KikqRKFBVjU4DO0rqTa7HAAA3IIg46MCAixKda5couEXAOCbCDI+jD4ZAIC75R2qMvXzE2R8GHvJAADcJb+0Rncv2aqRT3ysTXtKTKsj0LTPDLdLY0QGANDOKmsb9MKa7/XipzmqqW9cTPLF98U6p0cnU+ohyPiwdPaSAQC0E7vD0D835unJFdkqajrHb3BqJ903Pktnp8SYVhdBxoc1j8jkl9WosrZB4TZ+3ACAU/dJdpEe/e92fZdfLknqERume8Zl6pK+SbJYLKbWxjubD4sJC1bn8GAdqqxT7sFK9U2ONrskAIAXyS4o19x3t2tNdpEkKTo0SHdc3EvXn9dDwYGe0WZLkPFxaXHhOlRZp93FBBkAQOsUldfqqRXZenPDXjkMKchq0Q1DU3X7RT0VExZsdnkuCDI+Li0uXJv2lNDwCwA4qZp6u/72aY6eW/29KuvskqRL+yZp1rhM595knoYg4+NYgg0AOBmHw9Cyr/briQ926IfSGknSWd2idd/4LA1J62xydSdGkPFxGU0rl3IIMgCA41iXc1Bz392ur/eXSpK6xoTqd5eeoYlnJisgwNxG3tYgyPi4tLgISdLuogoZhmF6dzkAwDPkFFXosfe+04fbCiRJEbZA3Xphhm4anqaQIKvJ1bUeQcbH9YgNk8UildU06FBlnWIjbGaXBAAwUUllnf68aqdeW7dHDQ5D1gCLrhmSohmjeyvOC98jCDI+LiTIquToUO0/XK3dxZUEGQDwU7UNdr3y+R49/dFOldU0SJIuykzQvZdlqmdCpMnVtR1Bxg+kx4dr/+Fq5RRValCqZzdtAQDal2EY+u/X+Xrs/e3KO1QtSerTJUp/GN9Hw3vGmVzd6SPI+IG0uHB9urOYhl8A8DOb95Zo7rvbnYc6JkTaNPOSM3TFwG6yekEjb2sQZPxAunMJdoXJlQAAOkLeoSrNf/87Lf/fD5Kk0CCrfj0yXTePSFdYsG+99fvWV4PjSotvWrnEiIzHq7c7tO1AmZJjQhUfST8TgFNTWl2vZz/epZc/y1Wd3SGLRfrpwG6aeckZSowKMbs8tyDI+IHmEZncg1WyN3Wow3NU1DZozY4irdiWr4++K1RZTYMCLNKI3vGaPKCrxmYlKTTYe5ZCAuh49XaHFn+5VwtWZqukql6SNLxnrO69rI/PH09DkPEDyTGhCrYGqK7BoQOHq5XSOczskvxeYVmNVmwv0IptBfp810HV2R3O+yJtgSqvbdDqHUVavaNIEbZAXdY/SZMHdNO5aZ29YoMqAB3DMAyt3F6oee9tdx5F0zMhQvdelqkLz0jwi73DCDJ+wBpgUY/YMO0srFBOcSVBxgSGYWhXYYU+3FagD7cVaGveYZf70+LCNSYrUWOyEjWweyftPVSlpVv2663N+7SvpFpLNu7Tko371DUmVJMHdNXkgV2V0TRlCMA/fbO/VHPf3a4vcg5KkmLDgzVjTG9dMzhFgVbPOJm6I1gMwzDMLsKdysrKFB0drdLSUkVFRZldjmlufmWjPtxWoAcnZmnq8DSzy/ELdoehTXtKtGJbvlZsK1DuwSqX+89OidHYvokam5WojPiI4/7LyeEwtHFPiZZu2afl//tB5U17P0jSWSkxumJgV004M1mdwz3rNFoA7vNDabX++EG23tqyT4YhBQcG6Bfnp+mWURmKCgkyu7x209r3b0Zk/ER6fISkAhp+3ay6zq5PdxZpxbYCrfquUIcq65z3BVsDNLxnrMZkJWl0nwQltKLxLiDAoiFpnTUkrbMemNhXK7cXaOnm/VqdXaSteYe1Ne+wHnpnmy7MTNAVA7vqwswE2QLppwF8UWVtg55f871e+jRHNfWN09GXn52s315yhrp18t+RdoKMn2hu+GUvmfZ3sKJWq7YX6sNtBVq7q8j5F4wkRYcG6aLMBI3JStSI3vGKsLX9j1xIkFUTzkzWhDOTVVxRq/98dUBLt+zX1/tLtWJbY79NdGiQJpzZRVMGdtPA7jF+MT8O+Dq7w9A/N+bpjx9mq7iiVpI0qEcn/WFCls5OiTG3OA9AkPETafHNe8kQZNrD7uJK55TRxj0lOnqCtmtMqMb2bex3GZzaWUFumKuOi7DppvPTdNP5acouKNdbm/dr2Zb9yi+r0etf7tXrX+5VamyYJg/opskDuqp7rP/+aw3wZp9kF+nR/27Xd/nlkhrPz5t1aaYu7ZfEP1Sa0CPjJ4orajXokZWyWKTtD13qVSebegKHw9DWfYe1oqlZd1eh6+aC/bpGaUyfJI3JSlSfLpGm/AVjdxhal3NQ/968T+9/k6+qOrvzvsGpnTRlYDdd1r+LokN9Zw4d8FXZBeWa++52rckuktQ4unv7RT11w9BUBQf6RyNva9+/CTJ+wjAMnTnnQ5XXNOiDGSN0RpL3HhDWUWrq7fri+4P6cFuBVm0vUGF5rfO+wACLzkuP1ZisRI3OSlTXmFATKz1WVV2DPvg2X29t3q+1u4qdI0bBgQEa0ydRUwZ21Yje8W4ZLQLQdkXltXpqRbbe3LBXDkMKslp0/XmpuuPinooJ86+mfpp94cJisSg9Llxb95Vqd3EFQaYFpVX1+mhHY7/Jmh1FqjxqVCPCFqhRZ8RrTFaiRp2R4NEjG2HBgU3TSt2UX1qjt7/ar39v3qfsggq9+/UPevfrHxQbHqyJZyXrioHd1K9rFMPUgIlq6u3626c5em71986/dy7tm6RZ4zKV2tTjiOMjyPiR9PgIbd1XSsPvj+wrqWqcMvq2QOtzD8nuODJImRQVotFZCRqTlaTz0jt75YqgpOgQ/Xpkhm4eka5vD5Rp6Zb9evur/SquqNPCz3O18PNc9UyI0JSBXTXp7K5K9rDRJbMYhqGDlXXKLa5UVZ1dQdYABQcGyBbY+N/gpo9drlsD2LAQp8ThMLTsq/164oMd+qG0RpJ0Vrdo3Tc+S0PSOptcnXcgyPiRtObDI4v8O8gYhqFvD5Tpw6aVPtt/KHO5/4zESOfmdP27RvvMG5PFYlG/rtHq1zVa94zL1Kc7i/Xvzfu0oqnn5/H3d+iJD3ZoaHqspgzspkv7JZ3WKitvUVpdr9ziSu0+6pZ7sFK7iypVXttw8hf4kcAAi0vACbYeFX6ar1uPfOwMRce7Fvij60eFJ9txHuty/ahrQVYLI24eaF3OQc19d7u+3l8qSUqODtHvLs3UT85K9pm/dzqC7/8tBSdnkPHDEZl6u0Nf5hzSim35Wrm9UPsPVzvvC7BIg1I7a2xTeOkR6/vDuIHWAF2YmaALMxNUVlOv977+QW9t3q8vdx/S598f1OffH9TsZd/o0n5Jmjygq4b3jPPqM7qq6hqUW1x1JKQ0B5biSh08aq+fH7NYpOToUEWFBqmuwa46u0N1DQ7V2w3VNTT+/9HHS0hSg8NQQ51dkv34L2oCi0UKsgaoc1iweidF6ozECPVOjNQZSZHqlRDJWV5uZncY2nOwUtkF5dqRX6EdBWX6Lr/ceaRAhC1Qt4zK0C/OT2MhRhvQ7OtHvtlfqglPr1VseLA2zR5jdjluV15TrzXZRfrw2wJ9vKPQZVfc0CCrRvSO05isJF2UmcDOuE3yDlVp2Zb9emvLfpfAmxhl0+Vnd9WUgV2VmeSZf45qG+zKO1Sl3cVV2l1c4fxvbnGV8stqTvjchEibUuPClR4XrtS4cKU13bp3DjvpG4thGKqz/yjcNDhUZ7er9pjQY2/679GPtTufX/uj59c3GM7wVNsUmuoa7McEKZf/Nv3/0VOkJ2KxSD06h6l3YqQykyKbgk6kUuPCaQY/RYZhKL+sRjvyyxtvBeXKLijXzoIK1TY4jnl8gEW6Zkh3/WZMb8VFcNr9j7FqqQlB5ojK2gb1feADSdLW+8cqOsxzm1XbKr/0yGGMX3xfrHr7kV/vuIhgXZzZOOpyfq84/uVzAoZh6Ku8w3pr8369878DOtx0mq4kZXWJ0pSBXfWTs5OVEHny3YnbU4Pdof2Hq11GVHKaRln2l1TrRO/dMWFBjQEltjGkNAeW1Lhwn5xCszsM1dsdR8KR3aH80pqmUYEjb7SHWhiRCrYGKD0+XGckRR4JOYmR6hoTyrSHpMNVdfouv/yY7+fR/2A6WkhQgHolNI6CnZHYGBizukQpPpIA0xKCTBOCjKvzHl2l/LIaLb11mAZ072R2Oe3CMAyt3lGkP6/aqa9+dBhjely4xjSdZ3R2Sievnh4xS12DQx/vKNRbm/fpo+8KneEwwCKN6B2vyQO6amxWUrtNTzgchgrKa7S7qFK7m3pVcg82Bpa8Q1Uu4fTHwoOtSosPV2rskdGV1Kbw0olRt+MqKq91vhlnF5Q735yP3ofoaOHBVvU6KtickdR489URhaq6Bu0sqGgcXWkKKzvyy122YziaNcCitLjwI4Gl6XuV0jmMv39OEUGmCUHG1TUvrtMXOQf11JVnacrAbmaXc9p2FpTr4Xe365OmTaMsFmlASozGZDVuTtczgROi21NJZZ2Wf/2D3tq8T1v2HnZej7AF6rL+SZo8oJvOTet80n+xN68IcmmwParR9uhjHn4sODBAqbFhztGU9LjG4JIWH674CBtNre3A4TC0/3C1y/TIjvxyfV9U0WKQjA0Pdgk2vRMj1TsxQpFecohhvd2h3cWVx0wL7T1UpZbeJbt1CnWOrjQHu/T4cK9c3eiJCDJNCDKu7l36tRZ/uVe3X9RTd489w+xy2qyksk4LVmbrtS/3yu4wFGS1aNrwNP3ygrQOn+7wVzlFFc5+mn0lR5qnu8aEavKArpo8sKviImxtWhEUGGBRSuewpsASobS4xv+mxoUpOZqpDbPU2x3KLa50jko0j+LsOcGbfdeY0GOmpzISzHuzdzgM7SupdgloO/LLlVPcckiLizgqpDUFl14J3hPSvBVBpglBxtXfPs3RI+9u1/gzu+ivPx9odjmnrN7u0Gvr9mjByp0qrW7s2xiTlaj7LuvDplEmcTgMbcg9pKVb9uvd//3Q6iXLzSuC0o7qVWmeDurWKZRGUy9SVdegXYUVx4xmFJS1PP2SGhumzKSopoAQoTOSotS9HadfDMNQUUWtsvMrmoJXmXYUVGjnCabNImyB6p0Y4QxezaHFV6fNPB1BpglBxtWq7QX6xaKN6tMlSu/deYHZ5ZySj3cU6pHl2/R905LFzKRIzZ6QpeE940yuDM1q6u1asa1Ab23ep092FsvuMBQfaTvSZNvcvxLfuhVB8G6Hq+qcozZHj+KUtdAQawsMUK+mpeFH9+AkRYWccMqwrKZeO5v7e47qYyk5qkn9aMHWAGUkRDQuQ09ybWRmatJzcEQBjqt5L5nc4ko5HIZXDNHvKizXI+9u1+odjX0wncODdffY3rp6cHea5zxMSJBVE89K1sSzklVeUy+LxeKTK4LQOjFhwTo3PVbnpsc6rxmGoYKy2iOjJPkVym4awaltcOib/WX6Zr/rJpVRIYFHRkmSIhUeHKjswqaprfxyHSg9/vJ6i0VKjQ1vGmWJ0hlNoz89Ylla7kv4G8bPpHQOU2CARdX1dhWU16hLtOduR3+4qk4LVu7Uq+v2OPtgpg5L1W0X9fLoc47QiP4BHI/FYlFSdIiSokM0sne887rdYWjvoSqX3psdBeXaXVypspoGbcgt0YbckhZfNykqxKXRODMpUhnxEWz25wcIMn4myBqg7p3DlFPc2HDpiUGm3u7Q4i/36k8rs537l4zuk6j7xvdxjigB8C3Ny5bT4sJ1ab8k5/XaBru+L6x0mZ6qqmtQr4SjVgslRPrkvlhoHYKMH0qLC1dO00Ziwzysv2RNdpEeXr5NuworJDWeezR7QpbO7+VZdQLoGLZAq7KSo5SVTI8jjo8g44c88cylXYUVmvvuNn18VB/MXWN66+rBKQpkLhsA0AKCjB9Ki28MMjlFFSZX0tgH8+dVO/XqF3vU4DAUGNDYB3P7xfTBAABOjiDjhzxhRKbB7tDi9Xv11Iqj+2ASdO9lfZQez268AIDWIcj4oYymoJBXUq26BoeCAzt26uaTpj6YnU19ML0TIzR7QpYu6BV/kmcCAOCKIOOHEiJtCgu2qqrOrrySKmewcbfviyr06Lvbteq7QklSp7Ag3TWmt64Z0p0+GABAm3j0u8e8efM0ePBgRUZGKiEhQZMmTdKOHTvMLsvrWSyWI9NLRe6fXiqtqtdD72zTJX/6RKu+K1RggEU3DU/T6pkX6vqhqYQYAECbefSIzJo1azR9+nQNHjxYDQ0NuvfeezV27Fht27ZN4eHsJ3I60uLC9e2BMrf2yTTYHfpHUx9M81bhF2Um6L7xfTpsFAgA4Ns8Osi8//77Lh8vXLhQCQkJ2rRpk0aMGGFSVb4hvWlEJqfYPSuXPt3Z2AeTXdD4+r0SIvSHCVkuO3kCAHC6PDrI/FhpaakkqXPnzi0+pra2VrW1R05cLSsra/Gx/uzIEuz2HZHJKarQo//drpXbG/tgYpr6YH5OHwwAwA28Jsg4HA7NmDFDw4cPV79+/Vp83Lx58zRnzpwOrMw7pcc1Tu2019RSaXW9nl61U4u+yFW9vXE/mOuH9tCMi3uzdTgAwG28JshMnz5d33zzjdauXXvCx91zzz266667nB+XlZUpJSXF3eV5ndSmqaXC8lpV1Da0+YTiBrtDb2zI01MrsnWosk6SdOEZ8bpvfJZ6JtAHAwBwL68IMrfddpuWL1+uTz75RN26dTvhY202m2w2WwdV5r2iQ4MUFxGs4oo65RZXql/X6FN+jc92Feuhd7ZpR0G5JKlnQoT+ML6PRp2R0N7lAgBwXB4dZAzD0O23366lS5dq9erVSktLM7skn5IWF67iijrlnGKQ2V1cqbnvbtfK7QWSGvtgfjO6t35+bncF0QcDAOhAHh1kpk+frsWLF+vtt99WZGSk8vPzJUnR0dEKDQ01uTrvlxYXrg25Ja0+c6msprEPZuHnjX0w1gCLrj+vh2aM7qWYsGA3VwsAwLE8Osg899xzkqRRo0a5XH/55Zc1derUji/Ix6S1suHX7jD0xoa9eurDbB1s6oMZdUa8/jC+j3omRLq9TgAAWuLRQcYwDLNL8Gnp8Sc/PPLzXcV6aPk2fZff2AeTER+uP0zI0oX0wQAAPIBHBxm4V/pRxxQYhiGLxeK8L7e4Uo/+d7s+3NbYBxMdGqQZo3vpuvN60AcDAPAYBBk/1j02TBaLVF7boOKKOsVH2lRWU69nPtqllz/b7eyDue7c7poxurc6hdMHAwDwLAQZP2YLtKpbp1DlHarWzsJyrdhWoCc/3OHsgxnRO16zx/dRr0T6YAAAnokg4+fS4iKUd6hav351k8prGiQ19s7MHp+lUWfEu0w3AQDgaQgyfi49LlyfZBepvKZBUSGBmjG6t64fSh8MAMA7EGT83Lh+Sfrw23xd3CdRvxnTW53pgwEAeBGL4eNrnMvKyhQdHa3S0lJFRUWZXQ4AAGiF1r5/M38AAAC8FkEGAAB4LYIMAADwWgQZAADgtQgyAADAaxFkAACA1yLIAAAAr0WQAQAAXosgAwAAvBZBBgAAeC2CDAAA8FoEGQAA4LUIMgAAwGsRZAAAgNcKNLsAdzMMQ1LjceAAAMA7NL9vN7+Pt8Tng0x5ebkkKSUlxeRKAADAqSovL1d0dHSL91uMk0UdL+dwOHTgwAFFRkbKYrG02+uWlZUpJSVFeXl5ioqKarfXRdvxM/Es/Dw8Cz8Pz8LP4+QMw1B5ebmSk5MVENByJ4zPj8gEBASoW7dubnv9qKgofgk9DD8Tz8LPw7Pw8/As/DxO7EQjMc1o9gUAAF6LIAMAALwWQaaNbDabHnjgAdlsNrNLQRN+Jp6Fn4dn4efhWfh5tB+fb/YFAAC+ixEZAADgtQgyAADAaxFkAACA1yLIAAAAr0WQaaO//vWvSk1NVUhIiM4991ytX7/e7JL80rx58zR48GBFRkYqISFBkyZN0o4dO8wuC00ee+wxWSwWzZgxw+xS/Nr+/ft13XXXKTY2VqGhoerfv782btxodll+yW63a/bs2UpLS1NoaKgyMjL08MMPn/Q8IbSMINMGb775pu666y498MAD2rx5s8466yxdcsklKiwsNLs0v7NmzRpNnz5d69at04oVK1RfX6+xY8eqsrLS7NL83oYNG/TCCy/ozDPPNLsUv1ZSUqLhw4crKChI7733nrZt26Ynn3xSnTp1Mrs0vzR//nw999xzeuaZZ7R9+3bNnz9fjz/+uJ5++mmzS/NaLL9ug3PPPVeDBw/WM888I6nxPKeUlBTdfvvtmjVrlsnV+beioiIlJCRozZo1GjFihNnl+K2KigoNHDhQzz77rB555BGdffbZWrBggdll+aVZs2bps88+06effmp2KZA0YcIEJSYm6u9//7vz2hVXXKHQ0FC99tprJlbmvRiROUV1dXXatGmTRo8e7bwWEBCg0aNH64svvjCxMkhSaWmpJKlz584mV+Lfpk+frvHjx7v8OYE5/vOf/2jQoEH62c9+poSEBA0YMEAvvfSS2WX5rWHDhmnVqlXKzs6WJG3dulVr167VuHHjTK7Me/n8oZHtrbi4WHa7XYmJiS7XExMT9d1335lUFaTGkbEZM2Zo+PDh6tevn9nl+K033nhDmzdv1oYNG8wuBZJycnL03HPP6a677tK9996rDRs26I477lBwcLBuvPFGs8vzO7NmzVJZWZkyMzNltVplt9s1d+5cXXvttWaX5rUIMvAZ06dP1zfffKO1a9eaXYrfysvL05133qkVK1YoJCTE7HKgxoA/aNAgPfroo5KkAQMG6JtvvtHzzz9PkDHBkiVL9Prrr2vx4sXq27evvvrqK82YMUPJycn8PNqIIHOK4uLiZLVaVVBQ4HK9oKBASUlJJlWF2267TcuXL9cnn3yibt26mV2O39q0aZMKCws1cOBA5zW73a5PPvlEzzzzjGpra2W1Wk2s0P906dJFWVlZLtf69Omjf//73yZV5N9++9vfatasWbr66qslSf3799eePXs0b948gkwb0SNzioKDg3XOOedo1apVzmsOh0OrVq3S0KFDTazMPxmGodtuu01Lly7VRx99pLS0NLNL8msXX3yxvv76a3311VfO26BBg3Tttdfqq6++IsSYYPjw4cdsSZCdna0ePXqYVJF/q6qqUkCA61uv1WqVw+EwqSLvx4hMG9x111268cYbNWjQIA0ZMkQLFixQZWWlpk2bZnZpfmf69OlavHix3n77bUVGRio/P1+SFB0drdDQUJOr8z+RkZHH9CeFh4crNjaWviWT/OY3v9GwYcP06KOP6sorr9T69ev14osv6sUXXzS7NL80ceJEzZ07V927d1ffvn21ZcsWPfXUU7rpppvMLs17GWiTp59+2ujevbsRHBxsDBkyxFi3bp3ZJfklSce9vfzyy2aXhiYjR4407rzzTrPL8GvvvPOO0a9fP8NmsxmZmZnGiy++aHZJfqusrMy48847je7duxshISFGenq6cd999xm1tbVml+a12EcGAAB4LXpkAACA1yLIAAAAr0WQAQAAXosgAwAAvBZBBgAAeC2CDAAA8FoEGQAA4LUIMgB8XmpqqhYsWGB2GQDcgCADoF1NnTpVkyZNkiSNGjVKM2bM6LDPvXDhQsXExBxzfcOGDbr55ps7rA4AHYezlgB4vLq6OgUHB7f5+fHx8e1YDQBPwogMALeYOnWq1qxZoz//+c+yWCyyWCzKzc2VJH3zzTcaN26cIiIilJiYqOuvv17FxcXO544aNUq33XabZsyYobi4OF1yySWSpKeeekr9+/dXeHi4UlJSdOutt6qiokKStHr1ak2bNk2lpaXOz/fggw9KOnZqae/evbr88ssVERGhqKgoXXnllSooKHDe/+CDD+rss8/Wq6++qtTUVEVHR+vqq69WeXm5e79pAE4ZQQaAW/z5z3/W0KFD9atf/Uo//PCDfvjhB6WkpOjw4cO66KKLNGDAAG3cuFHvv/++CgoKdOWVV7o8f9GiRQoODtZnn32m559/XpIUEBCgv/zlL/r222+1aNEiffTRR/rd734nSRo2bJgWLFigqKgo5+ebOXPmMXU5HA5dfvnlOnTokNasWaMVK1YoJydHV111lcvjvv/+ey1btkzLly/X8uXLtWbNGj322GNu+m4BaCumlgC4RXR0tIKDgxUWFqakpCTn9WeeeUYDBgzQo48+6rz2//7f/1NKSoqys7PVu3dvSVKvXr30+OOPu7zm0f02qampeuSRR/R///d/evbZZxUcHKzo6GhZLBaXz/djq1at0tdff63du3crJSVFkvTKK6+ob9++2rBhgwYPHiypMfAsXLhQkZGRkqTrr79eq1at0ty5c0/vGwOgXTEiA6BDbd26VR9//LEiIiKct8zMTEmNoyDNzjnnnGOeu3LlSl188cXq2rWrIiMjdf311+vgwYOqqqpq9effvn27UlJSnCFGkrKyshQTE6Pt27c7r6WmpjpDjCR16dJFhYWFp/S1AnA/RmQAdKiKigpNnDhR8+fPP+a+Ll26OP8/PDzc5b7c3FxNmDBBt9xyi+bOnavOnTtr7dq1+sUvfqG6ujqFhYW1a51BQUEuH1ssFjkcjnb9HABOH0EGgNsEBwfLbre7XBs4cKD+/e9/KzU1VYGBrf8raNOmTXI4HHryyScVENA4mLxkyZKTfr4f69Onj/Ly8pSXl+ccldm2bZsOHz6srKysVtcDwDMwtQTAbVJTU/Xll18qNzdXxcXFcjgcmj59ug4dOqRrrrlGGzZs0Pfff68PPvhA06ZNO2EI6dmzp+rr6/X0008rJydHr776qrMJ+OjPV1FRoVWrVqm4uPi4U06jR49W//79de2112rz5s1av369brjhBo0cOVKDBg1q9+8BAPciyABwm5kzZ8pqtSorK0vx8fHau3evkpOT9dlnn8lut2vs2LHq37+/ZsyYoZiYGOdIy/GcddZZeuqppzR//nz169dPr7/+uubNm+fymGHDhun//u//dNVVVyk+Pv6YZmGpcYro7bffVqdOnTRixAiNHj1a6enpevPNN9v96wfgfhbDMAyziwAAAGgLRmQAAIDXIsgAAACvRZABAABeiyADAAC8FkEGAAB4LYIMAADwWgQZAADgtQgyAADAaxFkAACA1yLIAAAAr0WQAQAAXosgAwAAvNb/B9W1qSslM7R4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  598  253  105 7174   43  242 4211    2]]\n",
      "Translation: <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage of translate_sentence\n",
    "sentence = \"how are you today i am good?\"\n",
    "# sentence = \" \".join([list(en_vocab.keys())[list(en_vocab.values()).index(i)] for i in en_data[4]][1:-1])\n",
    "translation = translate_sentence(sentence, en_vocab, fi_vocab, encoder, decoder)\n",
    "print(\"Translation:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are you today i am good?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 149), 1258)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.shape, len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
